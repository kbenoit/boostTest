{
    "contents" : "urlregex <- \"(?i)\\\\b((?:[a-z][\\\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\\\d{0,3}[.]|[a-z0-9.\\\\-]+[.][a-z]{2,4}/)(?:[^\\\\s()<>]+|\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\))+(?:\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\)|[^\\\\s`!()\\\\[\\\\]{};:\\\\'\\\".,<>?]))\"\n\n\n#' @rdname clean\n#' @details \\code{cleanC} is KB's adaptation from KW's code for tokenization and cleaning, \n#' for testing.\n#' @importFrom Rcpp evalCpp\n#' @useDynLib quanteda\n#' @examples\n#' cleanC(\"This is 1 sentence with 2.0 numbers in it, and one comma.\", removeDigits=FALSE)\n#' cleanC(\"This is 1 sentence with 2.0 numbers in it, and one comma.\", toLower=FALSE)\n#' cleanC(\"We are his Beliebers, and him is #ourjustin @@justinbieber we luv u\", removeTwitter=TRUE)\n#' cleanC(\"Collocations can be represented as inheritance_tax using the _ character.\")\n#' cleanC(\"But under_scores can be removed with removeAdditional.\", removeAdditional=\"[_]\")\n#' cleanC(\"This is a $1,500,000 budget and $20bn cash and a $5 cigar.\")\n#' cleanC(\"This is a $1,500,000 budget and $20bn cash and a $5 cigar.\", removeDigits=FALSE)\n#' clean(\"URL regex from http://daringfireball.net/2010/07/improved_regex_for_matching_urls.\")\n#' \n#' \\donttest{# on a single long text\n#' mobydick <- texts(corpus(textfile(\"~/Dropbox/QUANTESS/corpora/project_gutenberg/pg2701.txt\")))\n#' system.time(tmp <- cleanC(mobydick)) # .218 seconds\n#' system.time(tmp <- clean(mobydick))  # .776 seconds\n#' \n#' # on a longer set of texts (34,070 texts)\n#' load('~/Dropbox/QUANTESS/Manuscripts/Collocations/Corpora/lauderdaleClark/Opinion_files.RData')\n#' txts <- unlist(Opinion_files[1]); names(txts) <- NULL\n#' system.time(tmp <- sapply(txts, cleanC)) # about 20.5 seconds\n#' \\dontrun{system.time(tmp <- sapply(txts, clean))  # about forever: 647.502 seconds}\n#' }\n#' @export\ncleanC <- function(x, removeDigits=TRUE, removePunct=TRUE, toLower=TRUE, \n                   removeAdditional=NULL, removeTwitter=FALSE, removeURL=TRUE, ...) {\n    \n    # to match the NULL default in clean()\n    if (is.null(removeAdditional)) removeAdditional <- \"\" \n    \n    tokenizecpp(x, removeDigits=removeDigits, removePunct=removePunct, \n             toLower=toLower, \n             removeAdditional=removeAdditional, \n             removeTwitter=removeTwitter, removeURL=removeURL)\n}    \n\n\n\n#' simple cleaning of text before processing\n#' \n#' \\code{clean} removes punctuation and digits from text, using the regex \n#' character classes for punctuation and digits. \\code{clean} uses the standard R\n#' function \\code{tolower} to convert the text to lower case. Each of these \n#' steps is optional, but switched on by default, so for example, to remove \n#' punctuation and convert to lower, but keep digits, the command would be: \n#' \\code{clean(mytexts, removeDigits=FALSE)}\n#' @rdname clean\n#' @param x The object to be cleaned. Can be either a character vector or a \n#'   corpus object. If x is a corpus, \\code{clean} returns the corpus containing \n#'   the cleaned texts.\n#' @param removeDigits remove numbers if \\code{TRUE}\n#' @param removePunct remove punctuation if \\code{TRUE}\n#' @param toLower convert text to lower case \\code{TRUE}\n#' @param removeTwitter if \\code{FALSE}, do not remove \\code{@@} or \\code{#}\n#' @param removeURL removes URLs (web addresses starting with \\code{http:} or \\code{https:}), based \n#' on a regular expression from \\url{http://daringfireball.net/2010/07/improved_regex_for_matching_urls}\n#' @param removeAdditional additional characters to remove (\\link[=regex]{regular expression})\n#' @param ... additional parameters\n#' @return A character vector equal in length to the original texts, after cleaning.\n#' @examples\n#' clean(\"This is 1 sentence with 2.0 numbers in it, and one comma.\", removeDigits=FALSE)\n#' clean(\"This is 1 sentence with 2.0 numbers in it, and one comma.\", toLower=FALSE)\n#' clean(\"We are his Beliebers, and him is #ourjustin @@justinbieber we luv u\", removeTwitter=TRUE)\n#' clean(\"Collocations can be represented as inheritance_tax using the _ character.\")\n#' clean(\"But under_scores can be removed with removeAdditional.\", removeAdditional=\"[_]\")\n#' clean(\"This is a $1,500,000 budget and $20bn cash and a $5 cigar.\")\n#' clean(\"This is a $1,500,000 budget and $20bn cash and a $5 cigar.\", removeDigits=FALSE)\n#' clean(\"URL regex from http://daringfireball.net/2010/07/improved_regex_for_matching_urls.\")\n#' \n#' # for a vector of texts\n#' clean(c(\"This is 1 sentence with 2.0 numbers in it, and one comma.\", \n#'         \"$1.2 billion was spent on text analysis in 2014.\"))\n#' @export\nclean <- function(x, ...) {\n    UseMethod(\"clean\")\n}\n\n\n#' @rdname clean\n#' @export\nclean.character <- function(x, removeDigits=TRUE, removePunct=TRUE, toLower=TRUE, \n                            removeAdditional=NULL, removeTwitter=FALSE, removeURL=TRUE, ...) {\n    ## THIS NEEDS TO LOOK AT SETTINGS BEFORE MAKING A DECISION\n    #if (!(removeDigits | removePunct | toLower) & is.null(removeAdditional)) {\n    #    warning(\"  clean: text unchanged\")\n    #}\n    \n    # convert \"curly quotes\"\n    x <- gsub(\"[\\u201C\\u201D]\", \"\\\"\", x)\n    x <- gsub(\"[\\u2018\\u2019]\", \"\\'\", x)\n    \n    urlregex <- \"(?i)\\\\b((?:[a-z][\\\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\\\d{0,3}[.]|[a-z0-9.\\\\-]+[.][a-z]{2,4}/)(?:[^\\\\s()<>]+|\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\))+(?:\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\)|[^\\\\s`!()\\\\[\\\\]{};:\\\\'\\\".,<>?]))\"\n    # see http://daringfireball.net/2010/07/improved_regex_for_matching_urls\n    if (removeURL) {\n        x <- gsub(urlregex, \"\", x, perl=TRUE)\n    } else {\n        # NEED TO PRESERVE THESE SOMEHOW\n    }\n    \n    # change typographic dash variations to a hyphen: There Can Be Only One\n    x <- gsub(\"[\\u2013\\u2014]\", \"-\", x)\n    \n    # remove tabs, newlines, and common cruft from word-processors\n    x <- gsub(\"\\\\f|[\\u2026\\u22EF]|\\\\t|\\\\n\", \" \", x)\n    \n    if (removePunct) {\n        # use \"negative lookahead\" to keep Twitter symbols, always keep \"_\"\n        # remove other punctuation from POSIX [:punct:]\n        remove <- paste(\"(?![\",\n                        ifelse(removeTwitter, \"_\", \"@#_\"),\n                        \"])[[:punct:]]\",  \n                        ifelse(!is.null(removeAdditional), paste(\"|\", removeAdditional, sep=\"\"), \"\"),\n                        sep=\"\")\n        x <- gsub(remove, \"\", x, perl=TRUE)\n    }\n    \n    if (removeDigits) \n        # amended regex removes currency stuff better, e.g.\n        # clean(\"This is a $5m watch and $20bn budget and $100,000 in cash plus a $5 cigar.\")\n        #\n        # 2nd part in alternation removes 1st 2nd 31st 43rd 3bis 101th etc.\n        #\n        # third part in alternation means don't remove digits if in a word, e.g. 4sure, crazy8\n        # the third stuff is to remove thousands separators, e.g. 1,000,000 or 1.000.000\n        # clean(\"nodigits crazy8 4sure 67 89b 1,000,000 1.023.496\")\n        # note: \\u00A3 is pound sign, \\u20AC is euro sign, \\u00A2 is the cent sign\n        x <- gsub(\"[$\\u00A3\\u20AC\\u00A2][[:digit:]]\\\\w*|\\\\b[[:digit:]]+(st|nd|rd|d|th|bis)\\\\b|\\\\b([[:digit:]]+[,.]?)+\\\\b\", \"\", x)\n    if (toLower) \n        x <- tolower(x)\n    \n    #     if (!is.null(removeAdditional))\n    #         x <- gsub(removeAdditional, \"\", x)\n    \n    # convert 2+ multiple whitespaces into one\n    x <- gsub(\"\\\\s{2,}\", \" \", x, perl=TRUE)\n    # remove leading and trailing whitespace and return\n    gsub(\"^\\\\s+|\\\\s+$\", \"\", x)\n}\n\n\n#' @rdname clean\n#' @export\nclean.corpus <- function(x, removeDigits=TRUE, removePunct=TRUE, toLower=TRUE,\n                         removeAdditional=NULL, removeTwitter=FALSE, ...) {\n    clean(texts(x), removeDigits=removeDigits, removePunct=removePunct, \n          toLower=toLower, removeAdditional=removeAdditional, ...)\n}\n",
    "created" : 1427321952692.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3707340553",
    "id" : "82029390",
    "lastKnownWriteTime" : 1427322120,
    "path" : "~/Dropbox/QUANTESS/boostTest/R/cleanC.R",
    "project_path" : "R/cleanC.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}